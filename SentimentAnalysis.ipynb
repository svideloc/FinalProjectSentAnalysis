{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# NTLK functions\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import tokenize as tok\n",
    "from nltk.stem.snowball import SnowballStemmer # load nltk's SnowballStemmer as variabled 'stemmer'\n",
    "import lda # topic modeling -NMF & LDA\n",
    "import string\n",
    "from nltk.tag import StanfordNERTagger\n",
    "\n",
    "# Load the LDA model from sk-learn\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "# Tf-Idf and Clustering packages\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import json\n",
    "\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "\n",
    "import keras\n",
    "import h5py\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('FebDebate#3.csv')\n",
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "df['text'] = df['text'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check nan's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get names of indexes for which column Age has value 30\n",
    "indexNames = df[df.text == 'nan'].index\n",
    " \n",
    "# Delete these row indexes from dataFrame\n",
    "df.drop(indexNames, inplace=True)\n",
    "\n",
    "(df.text == 'nan').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>retweets</th>\n",
       "      <th>permalink</th>\n",
       "      <th>date</th>\n",
       "      <th>formatted_date</th>\n",
       "      <th>favorites</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>geo</th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>biden</th>\n",
       "      <td>9846</td>\n",
       "      <td>9846</td>\n",
       "      <td>9846</td>\n",
       "      <td>9846</td>\n",
       "      <td>9846</td>\n",
       "      <td>9846</td>\n",
       "      <td>9846</td>\n",
       "      <td>9846</td>\n",
       "      <td>1930</td>\n",
       "      <td>1093</td>\n",
       "      <td>0</td>\n",
       "      <td>2268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bloomberg</th>\n",
       "      <td>9975</td>\n",
       "      <td>9975</td>\n",
       "      <td>9975</td>\n",
       "      <td>9975</td>\n",
       "      <td>9975</td>\n",
       "      <td>9975</td>\n",
       "      <td>9975</td>\n",
       "      <td>9975</td>\n",
       "      <td>1324</td>\n",
       "      <td>1055</td>\n",
       "      <td>0</td>\n",
       "      <td>3011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buttigieg</th>\n",
       "      <td>9612</td>\n",
       "      <td>9612</td>\n",
       "      <td>9612</td>\n",
       "      <td>9612</td>\n",
       "      <td>9612</td>\n",
       "      <td>9612</td>\n",
       "      <td>9612</td>\n",
       "      <td>9612</td>\n",
       "      <td>2377</td>\n",
       "      <td>1257</td>\n",
       "      <td>0</td>\n",
       "      <td>2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>klobuchar</th>\n",
       "      <td>9897</td>\n",
       "      <td>9897</td>\n",
       "      <td>9897</td>\n",
       "      <td>9897</td>\n",
       "      <td>9897</td>\n",
       "      <td>9897</td>\n",
       "      <td>9897</td>\n",
       "      <td>9897</td>\n",
       "      <td>3323</td>\n",
       "      <td>1512</td>\n",
       "      <td>0</td>\n",
       "      <td>2614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanders</th>\n",
       "      <td>9624</td>\n",
       "      <td>9624</td>\n",
       "      <td>9624</td>\n",
       "      <td>9624</td>\n",
       "      <td>9624</td>\n",
       "      <td>9624</td>\n",
       "      <td>9624</td>\n",
       "      <td>9624</td>\n",
       "      <td>1536</td>\n",
       "      <td>1074</td>\n",
       "      <td>0</td>\n",
       "      <td>1893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warren</th>\n",
       "      <td>9702</td>\n",
       "      <td>9702</td>\n",
       "      <td>9702</td>\n",
       "      <td>9702</td>\n",
       "      <td>9702</td>\n",
       "      <td>9702</td>\n",
       "      <td>9702</td>\n",
       "      <td>9702</td>\n",
       "      <td>1706</td>\n",
       "      <td>1146</td>\n",
       "      <td>0</td>\n",
       "      <td>1723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  author_id  text  retweets  permalink  date  formatted_date  \\\n",
       "search_term                                                                     \n",
       "biden        9846       9846  9846      9846       9846  9846            9846   \n",
       "bloomberg    9975       9975  9975      9975       9975  9975            9975   \n",
       "buttigieg    9612       9612  9612      9612       9612  9612            9612   \n",
       "klobuchar    9897       9897  9897      9897       9897  9897            9897   \n",
       "sanders      9624       9624  9624      9624       9624  9624            9624   \n",
       "warren       9702       9702  9702      9702       9702  9702            9702   \n",
       "\n",
       "             favorites  mentions  hashtags  geo  urls  \n",
       "search_term                                            \n",
       "biden             9846      1930      1093    0  2268  \n",
       "bloomberg         9975      1324      1055    0  3011  \n",
       "buttigieg         9612      2377      1257    0  2263  \n",
       "klobuchar         9897      3323      1512    0  2614  \n",
       "sanders           9624      1536      1074    0  1893  \n",
       "warren            9702      1706      1146    0  1723  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('search_term').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>retweets</th>\n",
       "      <th>permalink</th>\n",
       "      <th>date</th>\n",
       "      <th>formatted_date</th>\n",
       "      <th>favorites</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>geo</th>\n",
       "      <th>urls</th>\n",
       "      <th>search_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1232455231251730432</td>\n",
       "      <td>1049108900618940416</td>\n",
       "      <td>No wonder he wants to be president!!</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/rebellious_yell/status/123...</td>\n",
       "      <td>2020-02-25 23:59:59+00:00</td>\n",
       "      <td>Tue Feb 25 23:59:59 +0000 2020</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>warren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1232455227548192769</td>\n",
       "      <td>489991648</td>\n",
       "      <td>@realDonaldTrump Mike Bloomberg’s New TV Ad: I...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/jjsmaga7/status/1232455227...</td>\n",
       "      <td>2020-02-25 23:59:58+00:00</td>\n",
       "      <td>Tue Feb 25 23:59:58 +0000 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>@realDonaldTrump @MikeBloomberg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>warren</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id            author_id  \\\n",
       "0  1232455231251730432  1049108900618940416   \n",
       "1  1232455227548192769            489991648   \n",
       "\n",
       "                                                text  retweets  \\\n",
       "0               No wonder he wants to be president!!         0   \n",
       "1  @realDonaldTrump Mike Bloomberg’s New TV Ad: I...         0   \n",
       "\n",
       "                                           permalink  \\\n",
       "0  https://twitter.com/rebellious_yell/status/123...   \n",
       "1  https://twitter.com/jjsmaga7/status/1232455227...   \n",
       "\n",
       "                        date                  formatted_date  favorites  \\\n",
       "0  2020-02-25 23:59:59+00:00  Tue Feb 25 23:59:59 +0000 2020          1   \n",
       "1  2020-02-25 23:59:58+00:00  Tue Feb 25 23:59:58 +0000 2020          0   \n",
       "\n",
       "                          mentions hashtags  geo urls search_term  \n",
       "0                              NaN      NaN  NaN  NaN      warren  \n",
       "1  @realDonaldTrump @MikeBloomberg      NaN  NaN  NaN      warren  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 58656 entries, 0 to 59993\n",
      "Data columns (total 13 columns):\n",
      "id                58656 non-null int64\n",
      "author_id         58656 non-null int64\n",
      "text              58656 non-null object\n",
      "retweets          58656 non-null int64\n",
      "permalink         58656 non-null object\n",
      "date              58656 non-null object\n",
      "formatted_date    58656 non-null object\n",
      "favorites         58656 non-null int64\n",
      "mentions          12196 non-null object\n",
      "hashtags          7137 non-null object\n",
      "geo               0 non-null float64\n",
      "urls              13772 non-null object\n",
      "search_term       58656 non-null object\n",
      "dtypes: float64(1), int64(4), object(8)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Day/month as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parsing through the date and adding day/month/year/hour to the dataframe\n",
    "day = []\n",
    "month = []\n",
    "year = []\n",
    "hour = []\n",
    "formated_date = list(df.formatted_date)\n",
    "for i in formated_date:\n",
    "    x = parser.parse(i)\n",
    "    day.append(x.day)\n",
    "    month.append(x.month)\n",
    "    year.append(x.year)\n",
    "    hour.append(x.hour)\n",
    "\n",
    "#Adding to df\n",
    "df['day'] = day\n",
    "df['month'] = month\n",
    "df['year'] = year\n",
    "df['hour'] = hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby(['day', 'search_term']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for text data and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complie all regular expressions\n",
    "isURL = re.compile(r'http[s]?:// (?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', re.VERBOSE | re.IGNORECASE)\n",
    "isRTusername = re.compile(r'^RT+[\\s]+(@[\\w_]+:)',re.VERBOSE | re.IGNORECASE) #r'^RT+[\\s]+(@[\\w_]+:)'\n",
    "isEntity = re.compile(r'@[\\w_]+', re.VERBOSE | re.IGNORECASE)\n",
    "\n",
    "def clean_tweet(row):\n",
    "    row = isURL.sub(\"\",row)\n",
    "    row = isRTusername.sub(\"\",row)\n",
    "    row = isEntity.sub(\"\",row)\n",
    "    return row\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in tok.sent_tokenize(text) for word in tok.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>retweets</th>\n",
       "      <th>permalink</th>\n",
       "      <th>date</th>\n",
       "      <th>formatted_date</th>\n",
       "      <th>favorites</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>geo</th>\n",
       "      <th>urls</th>\n",
       "      <th>search_term</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1232455231251730432</td>\n",
       "      <td>1049108900618940416</td>\n",
       "      <td>No wonder he wants to be president!!</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/rebellious_yell/status/123...</td>\n",
       "      <td>2020-02-25 23:59:59+00:00</td>\n",
       "      <td>Tue Feb 25 23:59:59 +0000 2020</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>warren</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>23</td>\n",
       "      <td>No wonder he wants to be president</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1232455227548192769</td>\n",
       "      <td>489991648</td>\n",
       "      <td>@realDonaldTrump Mike Bloomberg’s New TV Ad: I...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/jjsmaga7/status/1232455227...</td>\n",
       "      <td>2020-02-25 23:59:58+00:00</td>\n",
       "      <td>Tue Feb 25 23:59:58 +0000 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>@realDonaldTrump @MikeBloomberg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>warren</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>23</td>\n",
       "      <td>Mike Bloomberg’s New TV Ad I Will Get It Done...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id            author_id  \\\n",
       "0  1232455231251730432  1049108900618940416   \n",
       "1  1232455227548192769            489991648   \n",
       "\n",
       "                                                text  retweets  \\\n",
       "0               No wonder he wants to be president!!         0   \n",
       "1  @realDonaldTrump Mike Bloomberg’s New TV Ad: I...         0   \n",
       "\n",
       "                                           permalink  \\\n",
       "0  https://twitter.com/rebellious_yell/status/123...   \n",
       "1  https://twitter.com/jjsmaga7/status/1232455227...   \n",
       "\n",
       "                        date                  formatted_date  favorites  \\\n",
       "0  2020-02-25 23:59:59+00:00  Tue Feb 25 23:59:59 +0000 2020          1   \n",
       "1  2020-02-25 23:59:58+00:00  Tue Feb 25 23:59:58 +0000 2020          0   \n",
       "\n",
       "                          mentions hashtags  geo urls search_term  day  month  \\\n",
       "0                              NaN      NaN  NaN  NaN      warren   25      2   \n",
       "1  @realDonaldTrump @MikeBloomberg      NaN  NaN  NaN      warren   25      2   \n",
       "\n",
       "   year  hour                                         text_clean  \n",
       "0  2020    23                 No wonder he wants to be president  \n",
       "1  2020    23   Mike Bloomberg’s New TV Ad I Will Get It Done...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove urls and retweets and entities from the text\n",
    "df['text_clean'] = df['text'].apply(lambda row:clean_tweet(row))\n",
    "\n",
    "#remove punctuations\n",
    "RE_PUNCTUATION = '|'.join([re.escape(x) for x in string.punctuation])  \n",
    "df['text_clean'] = df['text_clean'].str.replace(RE_PUNCTUATION, \"\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre Trained Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/svideloc/anaconda3/envs/learn-env/lib/python3.7/site-packages/keras/engine/saving.py:384: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 56, 100)           40000100  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               234496    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 40,371,310\n",
      "Trainable params: 371,210\n",
      "Non-trainable params: 40,000,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "weight_path = '../SentimentAnalysis/model/best_model.hdf5'\n",
    "prd_model = load_model(weight_path)\n",
    "prd_model.summary()\n",
    "word_idx = json.load(open(\"../SentimentAnalysis/Data/word_idx.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get sentiment score using trained weights from NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_DL(prd_model, text_data, word_idx):\n",
    "\n",
    "    #data = \"Pass the salt\"\n",
    "\n",
    "    live_list = []\n",
    "    batchSize = len(text_data)\n",
    "    live_list_np = np.zeros((56,batchSize))\n",
    "    for index, row in text_data.iterrows():\n",
    "        #print (index)\n",
    "        text_data_sample = text_data['text'][index]\n",
    "        # split the sentence into its words and remove any punctuations.\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        text_data_list = tokenizer.tokenize(text_data_sample)\n",
    "\n",
    "        #text_data_list = text_data_sample.split()\n",
    "\n",
    "\n",
    "        labels = np.array(['1','2','3','4','5','6','7','8','9','10'], dtype = \"int\")\n",
    "        #word_idx['I']\n",
    "        # get index for the live stage\n",
    "        data_index = np.array([word_idx[word.lower()] if word.lower() in word_idx else 0 for word in text_data_list])\n",
    "        data_index_np = np.array(data_index)\n",
    "\n",
    "        # padded with zeros of length 56 i.e maximum length\n",
    "        padded_array = np.zeros(56)\n",
    "        padded_array[:data_index_np.shape[0]] = data_index_np[:56]\n",
    "        data_index_np_pad = padded_array.astype(int)\n",
    "\n",
    "\n",
    "        live_list.append(data_index_np_pad)\n",
    "\n",
    "    live_list_np = np.asarray(live_list)\n",
    "    score = prd_model.predict(live_list_np, batch_size=batchSize, verbose=0)\n",
    "    single_score = np.round(np.dot(score, labels)/10,decimals=2)\n",
    "\n",
    "    score_all  = []\n",
    "    for each_score in score:\n",
    "\n",
    "        top_3_index = np.argsort(each_score)[-3:]\n",
    "        top_3_scores = each_score[top_3_index]\n",
    "        top_3_weights = top_3_scores/np.sum(top_3_scores)\n",
    "        single_score_dot = np.round(np.dot(top_3_index, top_3_weights)/10, decimals = 2)\n",
    "        score_all.append(single_score_dot)\n",
    "\n",
    "    text_data['Sentiment_Score'] = pd.DataFrame(score_all)\n",
    "\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Clean after Sentiment Included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>retweets</th>\n",
       "      <th>permalink</th>\n",
       "      <th>date</th>\n",
       "      <th>formatted_date</th>\n",
       "      <th>favorites</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>search_term</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1207812848254115847</td>\n",
       "      <td>1055637768485908485</td>\n",
       "      <td>Yeah, @JoeBiden?!?!?!?! #DemDebate</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/NinesMarie/status/12078128...</td>\n",
       "      <td>2019-12-19 23:59:57+00:00</td>\n",
       "      <td>Thu Dec 19 23:59:57 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>@JoeBiden</td>\n",
       "      <td>#DemDebate</td>\n",
       "      <td>https://twitter.com/mcpli/status/1207763584907...</td>\n",
       "      <td>biden</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>23</td>\n",
       "      <td>Yeah  DemDebate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1207812833414647808</td>\n",
       "      <td>1189920349082783745</td>\n",
       "      <td>Stay positive President Trump. We the people b...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/LloydPe73431132/status/120...</td>\n",
       "      <td>2019-12-19 23:59:54+00:00</td>\n",
       "      <td>Thu Dec 19 23:59:54 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>biden</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>23</td>\n",
       "      <td>Stay positive President Trump We the people be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1207812831887818752</td>\n",
       "      <td>223017524</td>\n",
       "      <td>Just have someone in the audience call Biden o...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/bradakibasama/status/12078...</td>\n",
       "      <td>2019-12-19 23:59:53+00:00</td>\n",
       "      <td>Thu Dec 19 23:59:53 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>biden</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>23</td>\n",
       "      <td>Just have someone in the audience call Biden o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1207812820081029127</td>\n",
       "      <td>1908816246</td>\n",
       "      <td>How many people of color did your 1994 crimina...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/joeraddi/status/1207812820...</td>\n",
       "      <td>2019-12-19 23:59:51+00:00</td>\n",
       "      <td>Thu Dec 19 23:59:51 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>biden</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>23</td>\n",
       "      <td>How many people of color did your 1994 crimina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1207812804209717248</td>\n",
       "      <td>940743747612172288</td>\n",
       "      <td>Which administration built the “cages???”</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/KenJ91572854/status/120781...</td>\n",
       "      <td>2019-12-19 23:59:47+00:00</td>\n",
       "      <td>Thu Dec 19 23:59:47 +0000 2019</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>biden</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>23</td>\n",
       "      <td>Which administration built the “cages”</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                   id            author_id  \\\n",
       "0      0  1207812848254115847  1055637768485908485   \n",
       "1      1  1207812833414647808  1189920349082783745   \n",
       "2      2  1207812831887818752            223017524   \n",
       "3      3  1207812820081029127           1908816246   \n",
       "4      4  1207812804209717248   940743747612172288   \n",
       "\n",
       "                                                text  retweets  \\\n",
       "0                 Yeah, @JoeBiden?!?!?!?! #DemDebate         0   \n",
       "1  Stay positive President Trump. We the people b...         0   \n",
       "2  Just have someone in the audience call Biden o...         0   \n",
       "3  How many people of color did your 1994 crimina...         0   \n",
       "4         Which administration built the “cages???”          0   \n",
       "\n",
       "                                           permalink  \\\n",
       "0  https://twitter.com/NinesMarie/status/12078128...   \n",
       "1  https://twitter.com/LloydPe73431132/status/120...   \n",
       "2  https://twitter.com/bradakibasama/status/12078...   \n",
       "3  https://twitter.com/joeraddi/status/1207812820...   \n",
       "4  https://twitter.com/KenJ91572854/status/120781...   \n",
       "\n",
       "                        date                  formatted_date  favorites  \\\n",
       "0  2019-12-19 23:59:57+00:00  Thu Dec 19 23:59:57 +0000 2019          0   \n",
       "1  2019-12-19 23:59:54+00:00  Thu Dec 19 23:59:54 +0000 2019          0   \n",
       "2  2019-12-19 23:59:53+00:00  Thu Dec 19 23:59:53 +0000 2019          0   \n",
       "3  2019-12-19 23:59:51+00:00  Thu Dec 19 23:59:51 +0000 2019          0   \n",
       "4  2019-12-19 23:59:47+00:00  Thu Dec 19 23:59:47 +0000 2019          6   \n",
       "\n",
       "    mentions    hashtags                                               urls  \\\n",
       "0  @JoeBiden  #DemDebate  https://twitter.com/mcpli/status/1207763584907...   \n",
       "1        NaN         NaN                                                NaN   \n",
       "2        NaN         NaN                                                NaN   \n",
       "3        NaN         NaN                                                NaN   \n",
       "4        NaN         NaN                                                NaN   \n",
       "\n",
       "  search_term  day  month  year  hour  \\\n",
       "0       biden   19     12  2019    23   \n",
       "1       biden   19     12  2019    23   \n",
       "2       biden   19     12  2019    23   \n",
       "3       biden   19     12  2019    23   \n",
       "4       biden   19     12  2019    23   \n",
       "\n",
       "                                          text_clean  \n",
       "0                                    Yeah  DemDebate  \n",
       "1  Stay positive President Trump We the people be...  \n",
       "2  Just have someone in the audience call Biden o...  \n",
       "3  How many people of color did your 1994 crimina...  \n",
       "4            Which administration built the “cages”   "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_datat_out = get_sentiment_DL(prd_model, text_data, word_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = text_datat_out.sort_values(by='Sentiment_Score')[['text', 'search_term', 'Sentiment_Score', 'retweets']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Am I really going to get my insomniac ass out of my lovely bed to find stupid CNN on my telly and watch the Democratic debate just to take the piss out of Biden? Yeap!'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>search_term</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>405</td>\n",
       "      <td>Am I really going to get my insomniac ass out ...</td>\n",
       "      <td>biden</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>871</td>\n",
       "      <td>Obama is dirty as the day is long. Why does no...</td>\n",
       "      <td>biden</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>205</td>\n",
       "      <td>Can you get me a job like you got hunter in Uk...</td>\n",
       "      <td>biden</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>ACA is crap, good riddance to bad garbage.</td>\n",
       "      <td>biden</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>603</td>\n",
       "      <td>Oh please. Remember Jared and Ivanka who made ...</td>\n",
       "      <td>biden</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>576</td>\n",
       "      <td>Hey Joe we wanted to keep our Doctor and we co...</td>\n",
       "      <td>biden</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>387</td>\n",
       "      <td>Trump can’t afford to wait til Biden is the no...</td>\n",
       "      <td>biden</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>874</td>\n",
       "      <td>That trailer looks amazing! I have seen many t...</td>\n",
       "      <td>biden</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>638</td>\n",
       "      <td>Wow I can’t believe you tweeted me! Thank you ...</td>\n",
       "      <td>biden</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>484</td>\n",
       "      <td>Truly! Love being back together with my #CC2C ...</td>\n",
       "      <td>biden</td>\n",
       "      <td>0.72</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                               text search_term  \\\n",
       "0      405  Am I really going to get my insomniac ass out ...       biden   \n",
       "1      871  Obama is dirty as the day is long. Why does no...       biden   \n",
       "2      205  Can you get me a job like you got hunter in Uk...       biden   \n",
       "3      120         ACA is crap, good riddance to bad garbage.       biden   \n",
       "4      603  Oh please. Remember Jared and Ivanka who made ...       biden   \n",
       "..     ...                                                ...         ...   \n",
       "995    576  Hey Joe we wanted to keep our Doctor and we co...       biden   \n",
       "996    387  Trump can’t afford to wait til Biden is the no...       biden   \n",
       "997    874  That trailer looks amazing! I have seen many t...       biden   \n",
       "998    638  Wow I can’t believe you tweeted me! Thank you ...       biden   \n",
       "999    484  Truly! Love being back together with my #CC2C ...       biden   \n",
       "\n",
       "     Sentiment_Score  retweets  \n",
       "0               0.05         0  \n",
       "1               0.06         0  \n",
       "2               0.06         1  \n",
       "3               0.07         0  \n",
       "4               0.07         0  \n",
       "..               ...       ...  \n",
       "995             0.71         0  \n",
       "996             0.71         0  \n",
       "997             0.72         0  \n",
       "998             0.72         0  \n",
       "999             0.72        19  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
